---
title: Lezione (2025-09-23)
---

## Lazy learning: astrazione

Il nostro obiettivo è quello di costruire una funzione $y = f(\mathbf{x})$.

Dobbiamo imporrre una restrizione, ovvero che l'argomento $\mathbf{x}$
appartenga allo stesso campo degli esempi che il sistema ha già visto.

Una **distribuzione di probabilità** rappresenta la probabilità che le
componenti dei vettori esempio assumano certi valori. La nostra $f$ darà
risultati attendibili solo quando i vettori esempio e quello che viene dato in
input seguono la stessa distribuzione di probabilità.

**Regressione**: output di un numero reale da $f(\mathbf{x})$.

## Apprendimento supervisionato

L'apprendimento supervisionato è solo uno dei modi di arrivare ad una funzione
che preso un input generale riesca a restituire un output.

La nostra funzione (d'ora in poi modello) esprimerà l'associazione tra l'input e
l'output dato attraverso dei parametri che possono essere modificati per
migliorare la correttezza dell'output.

$$
y = f(\mathbf{x}, \mathbf{w})
$$

Il processo di apprendimento sta nel trovare i migliori parametri in maniera
automatica. Ecco perchè si chiama machine learning.

### Come trovare i parametri

Iniziamo a calcolare $f$ sull'insieme degli esempi. Con parametri casuali il
modello darà risultati che possono essere giusti o sbagliati.

Definiamo una misura (che chiameremo **errore**) di quanto una risposta è
sbagliata rispetto a quella dell'etichetta dell'esempio dato. Il modo per
ottimizzare i parametri è quello di trovare il valore che minimizzi la funzione
di errore.

Una buona misura di errore può essere la somma degli errori fatti dalla funzione
sugli esempi al quadrato (aka la varianza):

$$
E(\mathbf{w}) = \sum_{i} (f(\mathbf{x}_i, \mathbf{w}) - y_i)^2
$$

Se $E(\mathbf{w})$ è una funzione continua, allora posso 'spostarmi' verso il
punto con il valore più basso (**gradient descent**).

Dato che il computer non può trovare il minimo della funzione in maniera visiva
(come farebbe un umano a colpo d'occhio), l'algoritmo che si usa è quello di
spostarsi di piccoli intervalli sulla funzione nella direzione del gradiente di
$E(w)$. In questo modo eventualmente arriverò ad un punto di minimo dove
$\nabla E(w) = 0$.

## Come testare un modello

Nell'apprendimento supervisionato, è importante tenere ben separati l'insieme di
dati esempio usati per l'allenamento e l'insieme di dati usati per testare la
performance del sistema.

Quindi un giudizio si può dare in base al numero di risposte corrette date dal
sistema sui dati di test su cui non è stato allenato.

Il metodo più corretto sarebbe quello di dividere in 3 insiemi i dati:

- **training set**: usati per ottimizzare i parametri attraverso il gradient
  descent;
- **validation set**: usati per validare un modello, dà risultati ottimistici
  perchè noi stiamo cambiando il modello per ottenere performance migliori su
  questo set;
- **testing set**: si usa come prova finale per vedere se ci sono discrepanze
  tra il validation set e un caso più generale;

### $K$-fold cross-validation

Tecnica usata per decidere come suddividere i dati esempio nei 2 insiemi di
training e validazione.

1. Divido l'insieme totale in $K$ sottoinsiemi.
2. Ne tengo uno da parte come validation set.
3. Ogni volta che cambio il modello scelgo un'altro sottoinsieme di dati come
   validation set.
4. Faccio una media tra tutti i risultati di validazione.

Come scegliere un valore ottimale di $K$? La ricerca è ancora in corso.
