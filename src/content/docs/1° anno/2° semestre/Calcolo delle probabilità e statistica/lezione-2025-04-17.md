---
title: Lezione (2025-04-17)
---

# Modelli di variabili aleatorie discrete (parte 2)

## Binomiale negativa (aka Pascal)

$$
X \sim NB(m,p)
$$

Consideriamo la variabile aleatoria uguale al numero $Y$ di successi ($1$) sino
a registrare $m$ insuccessi ($0$). Ogni esperimento ha probabilità $p$ di
successo e $1-p$ di insuccesso.

La Binomiale Negativa corrisponde alla somma di $m$ variabili geometriche
equidistribuite ed indipendenti.

- $P_{Y}(y) = \binom{y+m-1}{m}\ p^{y}\ (1-p)^{m}$, probabilità di realizzare $m$
  insuccessi (compreso l'ultimo) in $y + m$ esperimenti.
- $\Phi_{Y}(t) = \mathbb{E}[e^{t\ \sum_{i=1}^{m} X_{i}}] = \frac{(1-p)^{m}}{(1-e^{t}\ p)^{m}}$
- $\mathbb{E}[Y] = \frac{m\ p}{1-p}$

## Ipergeometrica

$$
K \sim HG(N, D, n)
$$

Da un insieme di $N$ elementi se ne estraggono senza rimessa $D$ elementi non
conformi.

Estrarre un elemento non conforme indica il successo e la variabile assume
valore $1$, estrarne uno conforme indica insuccesso e ha valore $0$.

$k$ indica il numero di elementi non conformi presenti in un campione di $n$
elementi estratti tra gli $N$.

- $P_{K}(k) = \frac{\binom{D}{k}\ \binom{N-D}{n-k}}{\binom{N}{n}}$,
  $\max \Set{0,n-N+D} \leq k \leq \min \Set{D,n}$

Ogni estrazione è una variabile aleatoria Bernoulliana con $p = \frac{D}{N}$, se
si ipotizza di non conoscere il risultato delle precedenti estrazioni.

- $\mathbb{E}[K] = n \frac{D}{N}$

## Poissoniana

$$
X \sim Poi(\mu)
$$

Consideriamo una variabile aleatoria Binomiale $Y$ e supponiamo che $p \to 0$ e
$n \to \infty$, tali che $\frac{y}{n} \to 0$ e $n\ p = \mu$.

- $P_{X}(x) = \frac{\mu^{x}}{x!}\ e^{-\mu}$, approssimazione di MacLaurin di
  $P_{Y}$.
- $\Phi_{X}(t) = e^{\mu\ (e^{t} - 1)}$
- $\mathbb{E}[X] = \mu$
- $\mathbb{E}[X^{2}] = \mu^{2} + \mu$
- $Var[X] = \mu$

La somma di 2 variabili Poissoniane indipendenti $Z = X_{1} + X_{2}$ è un'altra
variabile aleatoria Poissoniana con $\mu_{Z} = \mu_{X_{1}} + \mu_{X_{2}}$.
